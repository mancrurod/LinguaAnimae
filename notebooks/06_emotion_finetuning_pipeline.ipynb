{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13674b81",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 1️⃣ Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c02f41f",
   "metadata": {},
   "source": [
    "## Emotion Classification Pipeline for Biblical Verses\n",
    "\n",
    "This notebook documents the full process of exploring, comparing and fine-tuning emotion classification models on biblical text, with a focus on the Book of Genesis and a final fine-tuning using a custom-annotated corpus.\n",
    "\n",
    "**Outline:**\n",
    "1. Model Benchmarking on Genesis\n",
    "2. Data Preparation for Fine-tuning\n",
    "3. Semi-automatic Labeling using GPT-4o\n",
    "4. Fine-tuning SamLowe/roberta-base-go_emotions\n",
    "5. Evaluation and Comparison with Previous Models\n",
    "6. Inference Examples and Analysis\n",
    "\n",
    "---\n",
    "\n",
    "**Project context:**  \n",
    "Emotion and theme detection in Bible verses for narrative and literary research, using NLP and modern transformer models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f58fcb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 2️⃣ Benchmarking Pretrained Models on Genesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39880916",
   "metadata": {},
   "source": [
    "## 1. Benchmarking Existing Models\n",
    "\n",
    "We begin by testing several HuggingFace models (Hartmann, GoEmotions/SamLowe, Bhadresh Savani, Joeddav) on Genesis.  \n",
    "The goal is to observe their behaviour on literary, ancient text before committing to any single approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "126280f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "904d687c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/processed/bible_kjv/1_genesis_emotion_comparison.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/processed/bible_kjv/1_genesis_emotion_comparison.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m display(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Plot emotion distributions\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/processed/bible_kjv/1_genesis_emotion_comparison.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/bible_kjv/1_genesis_emotion_comparison.csv\")\n",
    "display(df.head())\n",
    "\n",
    "# Plot emotion distributions\n",
    "plt.figure()\n",
    "sns.countplot(x=\"hartmann_label\", data=df, order=df['hartmann_label'].value_counts().index)\n",
    "plt.title(\"Hartmann Emotion Distribution\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "sns.countplot(x=\"goemotions_ekman_label\", data=df, order=df['goemotions_ekman_label'].value_counts().index)\n",
    "plt.title(\"GoEmotions (Ekman) Distribution\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "sns.countplot(x=\"bsavani_label\", data=df, order=df['bsavani_label'].value_counts().index)\n",
    "plt.title(\"Bhadresh Savani Emotion Distribution\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "sns.countplot(x=\"joeddav_ekman_label\", data=df, order=df['joeddav_ekman_label'].value_counts().index)\n",
    "plt.title(\"Joeddav (Ekman) Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b98987c",
   "metadata": {},
   "source": [
    "### **Observations:**\n",
    "- GoEmotions produces a strong \"neutral\" bias on Genesis.\n",
    "- Hartmann and bsavani force more emotion categories, but may overfit to their social-media source.\n",
    "- Joeddav shows a different distribution, with many \"surprise\" and \"joy\".\n",
    "- None of the available models fit perfectly for literary or biblical style.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72919bf3",
   "metadata": {},
   "source": [
    "# 3️⃣ Preparing a Custom Dataset for Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbff26c",
   "metadata": {},
   "source": [
    "## 2. Preparing a Custom Dataset for Fine-tuning\n",
    "\n",
    "Given the above, we decided to build a custom, hand-verified emotion-labeled dataset, leveraging GPT-4o for fast annotation and manual review.\n",
    "- 1000 unique verses were sampled from the full KJV.\n",
    "- Each verse was labeled with one of: joy, sadness, anger, fear, disgust, surprise, neutral.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c079299a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>verse_id</th>\n",
       "      <th>verse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>657</td>\n",
       "      <td>jeremiah_50_43</td>\n",
       "      <td>The king of Babylon hath heard the report of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>488</td>\n",
       "      <td>deuteronomy_30_15</td>\n",
       "      <td>See, I have set before thee this day life and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>520</td>\n",
       "      <td>luke_22_43</td>\n",
       "      <td>And there appeared an angel unto him from heav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>678</td>\n",
       "      <td>2_chronicles_2_1</td>\n",
       "      <td>And Solomon determined to build an house for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>acts_11_18</td>\n",
       "      <td>When they heard these things, they held their ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id           verse_id                                              verse\n",
       "657  657     jeremiah_50_43  The king of Babylon hath heard the report of t...\n",
       "488  488  deuteronomy_30_15  See, I have set before thee this day life and ...\n",
       "520  520         luke_22_43  And there appeared an angel unto him from heav...\n",
       "678  678   2_chronicles_2_1  And Solomon determined to build an house for t...\n",
       "21    21         acts_11_18  When they heard these things, they held their ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total verses sampled: 1000\n"
     ]
    }
   ],
   "source": [
    "# Show sample of selected verses\n",
    "df_samples = pd.read_csv(\"../data/evaluation/emotion_verses_to_label.csv\")\n",
    "display(df_samples.sample(5))\n",
    "print(f\"Total verses sampled: {len(df_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405e0d8e",
   "metadata": {},
   "source": [
    "# 4️⃣ Labeling Verses with GPT-4o (Semi-automatic Annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dce2ff1",
   "metadata": {},
   "source": [
    "## 3. Semi-automatic Annotation using GPT-4o\n",
    "\n",
    "Annotation prompt for GPT-4o:\n",
    "\n",
    "> Assign ONE main human emotion to each Bible verse below.  \n",
    "> Choose ONLY from this list: joy, sadness, anger, fear, disgust, surprise, neutral  \n",
    "> Return in CSV format with columns: id,verse_id,label  \n",
    "> [See appendix for full prompt.]\n",
    "\n",
    "Labels were reviewed and corrected as needed before proceeding to fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d62e0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>verse_id</th>\n",
       "      <th>verse</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>959</td>\n",
       "      <td>mark_1_12</td>\n",
       "      <td>And immediately the Spirit driveth him into th...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>682</td>\n",
       "      <td>ezekiel_27_28</td>\n",
       "      <td>The suburbs shall shake at the sound of the cr...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>289</td>\n",
       "      <td>psalms_102_11</td>\n",
       "      <td>My days are like a shadow that declineth; and ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>786</td>\n",
       "      <td>genesis_31_11</td>\n",
       "      <td>And the angel of God spake unto me in a dream,...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>810</td>\n",
       "      <td>acts_9_24</td>\n",
       "      <td>But their laying await was known of Saul. And ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id       verse_id                                              verse  \\\n",
       "959  959      mark_1_12  And immediately the Spirit driveth him into th...   \n",
       "682  682  ezekiel_27_28  The suburbs shall shake at the sound of the cr...   \n",
       "289  289  psalms_102_11  My days are like a shadow that declineth; and ...   \n",
       "786  786  genesis_31_11  And the angel of God spake unto me in a dream,...   \n",
       "810  810      acts_9_24  But their laying await was known of Saul. And ...   \n",
       "\n",
       "        label  \n",
       "959   neutral  \n",
       "682      fear  \n",
       "289   sadness  \n",
       "786  surprise  \n",
       "810      fear  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labeled verses: 1000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show labeled data (post-GPT + manual review)\n",
    "df_labeled = pd.read_csv(\"../data/evaluation/emotion_verses_labeled_2.csv\")\n",
    "display(df_labeled.sample(5))\n",
    "print(f\"Total labeled verses: {len(df_labeled)}\")\n",
    "\n",
    "plt.figure()\n",
    "sns.countplot(x=\"label\", data=df_labeled, order=sorted(df_labeled['label'].unique()))\n",
    "plt.title(\"Distribution of Labeled Emotions (Final Training Set)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bde710",
   "metadata": {},
   "source": [
    "# 5️⃣ Fine-tuning SamLowe/roberta-base-go_emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b80ac4",
   "metadata": {},
   "source": [
    "## 4. Fine-tuning SamLowe/roberta-base-go_emotions on Custom Labeled Data\n",
    "\n",
    "The fine-tuning uses 90% of the data for training and 10% for evaluation.  \n",
    "Labels are mapped to integer IDs as required by HuggingFace.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5c6783",
   "metadata": {},
   "source": [
    "We initialized the classification head (last layer) from scratch, as our label set consists of 7 mapped emotions, instead of the original 28 GoEmotions classes. The rest of the model loads all pre-trained weights, leveraging prior emotional knowledge. This is the recommended approach for transfer learning with a different output taxonomy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fab8dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "label\n",
      "6    799\n",
      "0    543\n",
      "1    371\n",
      "2    311\n",
      "3    303\n",
      "4    166\n",
      "5    109\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test:\n",
      "label\n",
      "6    80\n",
      "0    49\n",
      "1    46\n",
      "3    41\n",
      "2    36\n",
      "4    24\n",
      "5    14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Si usas train/test como pandas DataFrame\n",
    "print(\"Train:\")\n",
    "print(df_train['label'].value_counts())\n",
    "print(\"\\nTest:\")\n",
    "print(df_test['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f43917",
   "metadata": {},
   "source": [
    "### Cross validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11eb3cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 7800/7800 [00:00<00:00, 22441.77 examples/s]\n",
      "Map: 100%|██████████| 1951/1951 [00:00<00:00, 26083.22 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 - Macro F1: 0.455\n",
      "{'eval_loss': 1.150935411453247, 'eval_macro_f1': 0.4548368585368057, 'eval_runtime': 12.9029, 'eval_samples_per_second': 151.206, 'eval_steps_per_second': 4.728, 'epoch': 1.0}\n",
      "\n",
      "Fold 1 - Macro F1: 0.515\n",
      "{'eval_loss': 1.0705690383911133, 'eval_macro_f1': 0.514635989591712, 'eval_runtime': 4.9489, 'eval_samples_per_second': 394.231, 'eval_steps_per_second': 12.326, 'epoch': 2.0}\n",
      "\n",
      "Fold 1 - Macro F1: 0.537\n",
      "{'eval_loss': 1.0767254829406738, 'eval_macro_f1': 0.5374697373946126, 'eval_runtime': 4.4595, 'eval_samples_per_second': 437.494, 'eval_steps_per_second': 13.679, 'epoch': 3.0}\n",
      "\n",
      "Fold 1 - Macro F1: 0.537\n",
      "{'eval_loss': 1.0771472454071045, 'eval_macro_f1': 0.5373530932247517, 'eval_runtime': 4.4784, 'eval_samples_per_second': 435.642, 'eval_steps_per_second': 13.621, 'epoch': 4.0}\n",
      "{'train_runtime': 857.5282, 'train_samples_per_second': 36.384, 'train_steps_per_second': 2.276, 'train_loss': 1.0361291228747758, 'epoch': 4.0}\n",
      "\n",
      "Fold 1 - Macro F1: 0.537\n",
      "{'eval_loss': 1.0767254829406738, 'eval_macro_f1': 0.5374697373946126, 'eval_runtime': 4.4723, 'eval_samples_per_second': 436.24, 'eval_steps_per_second': 13.639, 'epoch': 4.0}\n",
      "\n",
      "=== Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 7801/7801 [00:00<00:00, 20540.01 examples/s]\n",
      "Map: 100%|██████████| 1950/1950 [00:00<00:00, 20252.86 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2 - Macro F1: 0.436\n",
      "{'eval_loss': 1.1780766248703003, 'eval_macro_f1': 0.43571469405472346, 'eval_runtime': 9.5669, 'eval_samples_per_second': 203.828, 'eval_steps_per_second': 6.376, 'epoch': 1.0}\n",
      "\n",
      "Fold 2 - Macro F1: 0.503\n",
      "{'eval_loss': 1.1164567470550537, 'eval_macro_f1': 0.5030821220285752, 'eval_runtime': 9.7374, 'eval_samples_per_second': 200.258, 'eval_steps_per_second': 6.264, 'epoch': 2.0}\n",
      "\n",
      "Fold 2 - Macro F1: 0.537\n",
      "{'eval_loss': 1.0923773050308228, 'eval_macro_f1': 0.5369503070964879, 'eval_runtime': 8.8644, 'eval_samples_per_second': 219.981, 'eval_steps_per_second': 6.881, 'epoch': 3.0}\n",
      "\n",
      "Fold 2 - Macro F1: 0.535\n",
      "{'eval_loss': 1.1012837886810303, 'eval_macro_f1': 0.5348441485849315, 'eval_runtime': 8.7083, 'eval_samples_per_second': 223.925, 'eval_steps_per_second': 7.005, 'epoch': 4.0}\n",
      "{'train_runtime': 1331.4587, 'train_samples_per_second': 23.436, 'train_steps_per_second': 1.466, 'train_loss': 1.0434469004146387, 'epoch': 4.0}\n",
      "\n",
      "Fold 2 - Macro F1: 0.537\n",
      "{'eval_loss': 1.0923773050308228, 'eval_macro_f1': 0.5369503070964879, 'eval_runtime': 9.3713, 'eval_samples_per_second': 208.081, 'eval_steps_per_second': 6.509, 'epoch': 4.0}\n",
      "\n",
      "=== Fold 3/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 7801/7801 [00:00<00:00, 20330.48 examples/s]\n",
      "Map: 100%|██████████| 1950/1950 [00:00<00:00, 23495.21 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3 - Macro F1: 0.441\n",
      "{'eval_loss': 1.141740322113037, 'eval_macro_f1': 0.4406317552118206, 'eval_runtime': 4.7469, 'eval_samples_per_second': 410.797, 'eval_steps_per_second': 12.851, 'epoch': 1.0}\n",
      "\n",
      "Fold 3 - Macro F1: 0.525\n",
      "{'eval_loss': 1.0721659660339355, 'eval_macro_f1': 0.5245043160778713, 'eval_runtime': 4.8342, 'eval_samples_per_second': 403.377, 'eval_steps_per_second': 12.618, 'epoch': 2.0}\n",
      "\n",
      "Fold 3 - Macro F1: 0.542\n",
      "{'eval_loss': 1.0595958232879639, 'eval_macro_f1': 0.5424518762569747, 'eval_runtime': 5.2367, 'eval_samples_per_second': 372.372, 'eval_steps_per_second': 11.649, 'epoch': 3.0}\n",
      "\n",
      "Fold 3 - Macro F1: 0.548\n",
      "{'eval_loss': 1.0727343559265137, 'eval_macro_f1': 0.5475306712384654, 'eval_runtime': 4.6887, 'eval_samples_per_second': 415.894, 'eval_steps_per_second': 13.01, 'epoch': 4.0}\n",
      "{'train_runtime': 383.376, 'train_samples_per_second': 81.393, 'train_steps_per_second': 5.092, 'train_loss': 1.0362818358374424, 'epoch': 4.0}\n",
      "\n",
      "Fold 3 - Macro F1: 0.548\n",
      "{'eval_loss': 1.0727343559265137, 'eval_macro_f1': 0.5475306712384654, 'eval_runtime': 4.704, 'eval_samples_per_second': 414.545, 'eval_steps_per_second': 12.968, 'epoch': 4.0}\n",
      "\n",
      "=== Fold 4/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 7801/7801 [00:00<00:00, 25077.00 examples/s]\n",
      "Map: 100%|██████████| 1950/1950 [00:00<00:00, 18206.63 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 - Macro F1: 0.460\n",
      "{'eval_loss': 1.1730468273162842, 'eval_macro_f1': 0.46009078789469404, 'eval_runtime': 4.7817, 'eval_samples_per_second': 407.803, 'eval_steps_per_second': 12.757, 'epoch': 1.0}\n",
      "\n",
      "Fold 4 - Macro F1: 0.493\n",
      "{'eval_loss': 1.0949796438217163, 'eval_macro_f1': 0.49346073086316805, 'eval_runtime': 5.3409, 'eval_samples_per_second': 365.105, 'eval_steps_per_second': 11.421, 'epoch': 2.0}\n",
      "\n",
      "Fold 4 - Macro F1: 0.514\n",
      "{'eval_loss': 1.1051301956176758, 'eval_macro_f1': 0.5141432585888426, 'eval_runtime': 4.9573, 'eval_samples_per_second': 393.355, 'eval_steps_per_second': 12.305, 'epoch': 3.0}\n",
      "\n",
      "Fold 4 - Macro F1: 0.526\n",
      "{'eval_loss': 1.1184967756271362, 'eval_macro_f1': 0.5258538493232302, 'eval_runtime': 5.2544, 'eval_samples_per_second': 371.117, 'eval_steps_per_second': 11.609, 'epoch': 4.0}\n",
      "{'train_runtime': 349.689, 'train_samples_per_second': 89.234, 'train_steps_per_second': 5.582, 'train_loss': 1.0572143304543418, 'epoch': 4.0}\n",
      "\n",
      "Fold 4 - Macro F1: 0.526\n",
      "{'eval_loss': 1.1184967756271362, 'eval_macro_f1': 0.5258538493232302, 'eval_runtime': 4.8184, 'eval_samples_per_second': 404.696, 'eval_steps_per_second': 12.66, 'epoch': 4.0}\n",
      "\n",
      "=== Fold 5/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 7801/7801 [00:00<00:00, 21477.06 examples/s]\n",
      "Map: 100%|██████████| 1950/1950 [00:00<00:00, 20845.27 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 5 - Macro F1: 0.467\n",
      "{'eval_loss': 1.1310807466506958, 'eval_macro_f1': 0.4669228333580676, 'eval_runtime': 4.2174, 'eval_samples_per_second': 462.367, 'eval_steps_per_second': 14.464, 'epoch': 1.0}\n",
      "\n",
      "Fold 5 - Macro F1: 0.492\n",
      "{'eval_loss': 1.0873554944992065, 'eval_macro_f1': 0.49154670686068497, 'eval_runtime': 4.1873, 'eval_samples_per_second': 465.697, 'eval_steps_per_second': 14.568, 'epoch': 2.0}\n",
      "\n",
      "Fold 5 - Macro F1: 0.515\n",
      "{'eval_loss': 1.0825508832931519, 'eval_macro_f1': 0.514564323977504, 'eval_runtime': 4.2836, 'eval_samples_per_second': 455.221, 'eval_steps_per_second': 14.24, 'epoch': 3.0}\n",
      "\n",
      "Fold 5 - Macro F1: 0.515\n",
      "{'eval_loss': 1.074852466583252, 'eval_macro_f1': 0.5152446739562164, 'eval_runtime': 4.4125, 'eval_samples_per_second': 441.925, 'eval_steps_per_second': 13.824, 'epoch': 4.0}\n",
      "{'train_runtime': 360.0521, 'train_samples_per_second': 86.665, 'train_steps_per_second': 5.421, 'train_loss': 1.0426089177366162, 'epoch': 4.0}\n",
      "\n",
      "Fold 5 - Macro F1: 0.515\n",
      "{'eval_loss': 1.074852466583252, 'eval_macro_f1': 0.5152446739562164, 'eval_runtime': 4.2326, 'eval_samples_per_second': 460.708, 'eval_steps_per_second': 14.412, 'epoch': 4.0}\n",
      "\n",
      "=== Cross-validation results (5 folds) ===\n",
      "Macro F1 per fold: [0.5374697373946126, 0.5369503070964879, 0.5475306712384654, 0.5258538493232302, 0.5152446739562164]\n",
      "Mean Macro F1: 0.533 | Std: 0.011\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, EarlyStoppingCallback\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import resample\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import Trainer\n",
    "\n",
    "# --- Compute class weights robustly ---\n",
    "def compute_class_weights(df, label_column, class_labels):\n",
    "    \"\"\"\n",
    "    Computes class weights for imbalanced classification.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Training dataframe.\n",
    "        label_column (str): Name of the label column.\n",
    "        class_labels (list): List of all class integer labels, in model's order.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Class weights as tensor, in order of class_labels.\n",
    "    \"\"\"\n",
    "    counts = df[label_column].value_counts().reindex(class_labels, fill_value=0).values\n",
    "    counts = np.maximum(counts, 1)  # Avoid division by zero\n",
    "    weights = 1.0 / counts\n",
    "    # No need to normalize: CrossEntropyLoss expects unnormalized weights\n",
    "    weights_tensor = torch.tensor(weights, dtype=torch.float32)\n",
    "    print(\"Class labels:\", class_labels)\n",
    "    print(\"Class counts:\", counts)\n",
    "    print(\"Class weights:\", weights)\n",
    "    return weights_tensor\n",
    "\n",
    "def focal_loss(logits, labels, alpha=1.0, gamma=2.0, weight=None):\n",
    "    \"\"\"\n",
    "    Compute focal loss for multi-class classification.\n",
    "    Args:\n",
    "        logits (Tensor): [batch_size, num_classes]\n",
    "        labels (Tensor): [batch_size]\n",
    "        alpha (float or Tensor, optional): Class weighting factor.\n",
    "        gamma (float): Focusing parameter.\n",
    "        weight (Tensor, optional): Class weights (as in CrossEntropyLoss).\n",
    "    \"\"\"\n",
    "    ce_loss = F.cross_entropy(logits, labels, weight=weight, reduction='none')\n",
    "    pt = torch.exp(-ce_loss)\n",
    "    focal = (alpha * (1 - pt) ** gamma * ce_loss)\n",
    "    return focal.mean()\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\", None)\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\", None)\n",
    "        if labels is not None and logits is not None:\n",
    "            if not isinstance(labels, torch.Tensor):\n",
    "                labels = torch.tensor(labels)\n",
    "            labels = labels.to(logits.device).long()\n",
    "            # Eliminar uso de weights, solo usar CrossEntropyLoss\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()  # Sin pesos de clase\n",
    "            loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "        return (0.0, outputs) if return_outputs else 0.0\n",
    "\n",
    "\n",
    "# --- 1. Load and shuffle data ---\n",
    "df = pd.read_csv(\"../data/evaluation/verses_parsed/emotion_verses_labeled_combined.csv\")\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "def clean_verse(text):\n",
    "    import re\n",
    "    # Quita saltos de línea, múltiples espacios, referencias tipo [1]\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\[\\d+\\]', '', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "df['verse'] = df['verse'].apply(clean_verse)\n",
    "\n",
    "# --- 2. Mapping and validation ---\n",
    "EMOTION_MAP = {\n",
    "    \"joy\": \"Alegría\",\n",
    "    \"sadness\": \"Tristeza\",\n",
    "    \"anger\": \"Ira\",\n",
    "    \"fear\": \"Miedo\",\n",
    "    \"surprise\": \"Sorpresa\",\n",
    "    \"disgust\": \"Asco\",\n",
    "    \"neutral\": \"Neutral\"\n",
    "}\n",
    "label_list = list(EMOTION_MAP.keys())            # List of string labels, e.g. ['joy', 'sadness', ...]\n",
    "label2id = {l: i for i, l in enumerate(label_list)}  # Mapping to int, order matches label_list\n",
    "id2label = {i: l for i, l in enumerate(label_list)}\n",
    "df['label'] = df['label'].str.strip().str.lower()\n",
    "invalid_labels = set(df['label'].unique()) - set(label_list)\n",
    "if invalid_labels:\n",
    "    print(f\"❌ ERROR: Detected invalid labels: {invalid_labels}\")\n",
    "    raise ValueError(\"Your CSV contains labels not present in the expected set.\")\n",
    "df['label'] = df['label'].map(label2id).astype(int)\n",
    "\n",
    "# --- 3. Cross-validation setup ---\n",
    "k = 5  # Number of folds\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "results = []\n",
    "CV_OUTPUT_DIR = \"./results_finetuned_bible_cv\"\n",
    "os.makedirs(CV_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(df['verse'], df['label'])):\n",
    "    print(f\"\\n=== Fold {fold+1}/{k} ===\")\n",
    "    df_train, df_test = df.iloc[train_idx].copy(), df.iloc[test_idx].copy()\n",
    "\n",
    "    # --- OPTIONAL OVERSAMPLING ---\n",
    "    # max_n = df_train['label'].value_counts().max()\n",
    "    # dfs = []\n",
    "    # for label in df_train['label'].unique():\n",
    "    #     df_label = df_train[df_train['label'] == label]\n",
    "    #     dfs.append(resample(df_label, replace=True, n_samples=max_n, random_state=fold))\n",
    "    # df_train = pd.concat(dfs).sample(frac=1, random_state=fold).reset_index(drop=True)\n",
    "    # print(\"Balanced train label counts:\\n\", df_train['label'].value_counts())\n",
    "\n",
    "    # --- Build datasets (renaming for HF compatibility) ---\n",
    "    ds = DatasetDict({\n",
    "        \"train\": Dataset.from_pandas(df_train[['verse', 'label']].rename(columns={'verse': 'text', 'label': 'labels'}), preserve_index=False),\n",
    "        \"test\": Dataset.from_pandas(df_test[['verse', 'label']].rename(columns={'verse': 'text', 'label': 'labels'}), preserve_index=False),\n",
    "    })\n",
    "\n",
    "    # --- Tokenizer and model ---\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"SamLowe/roberta-base-go_emotions\",\n",
    "        num_labels=len(label_list),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "    model.config.problem_type = \"single_label_classification\"\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        return tokenizer(examples[\"text\"], truncation=True, padding=True)\n",
    "\n",
    "    tokenized_datasets = ds.map(preprocess_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "    # Define unique subfolder for this fold:\n",
    "    fold_output_dir = os.path.join(CV_OUTPUT_DIR, f\"fold_{fold+1}\")\n",
    "\n",
    "    # --- Training arguments ---\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=fold_output_dir,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=1e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=32,\n",
    "        gradient_accumulation_steps=1,\n",
    "        num_train_epochs=4,\n",
    "        weight_decay=0.05,\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"macro_f1\",\n",
    "        greater_is_better=True,\n",
    "        save_total_limit=2,\n",
    "        logging_strategy=\"no\",\n",
    "        report_to=\"none\",\n",
    "        seed=42 + fold,\n",
    "        push_to_hub=False,\n",
    "        disable_tqdm=True,\n",
    "    )\n",
    "\n",
    "    # --- Metrics ---\n",
    "    def compute_metrics(pred):\n",
    "        preds = np.argmax(pred.predictions, axis=1)\n",
    "        labels = pred.label_ids\n",
    "        report = classification_report(labels, preds, target_names=[id2label[i] for i in range(len(label_list))], output_dict=True, zero_division=0)\n",
    "        macro_f1 = report[\"macro avg\"][\"f1-score\"]\n",
    "        print(f\"\\nFold {fold+1} - Macro F1: {macro_f1:.3f}\")\n",
    "        return {\"macro_f1\": macro_f1}\n",
    "\n",
    "    # --- Trainer ---\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"test\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    results.append(metrics)\n",
    "\n",
    "# --- Show CV results ---\n",
    "macro_f1s = [r[\"eval_macro_f1\"] for r in results]\n",
    "print(f\"\\n=== Cross-validation results ({k} folds) ===\")\n",
    "print(f\"Macro F1 per fold: {macro_f1s}\")\n",
    "print(f\"Mean Macro F1: {np.mean(macro_f1s):.3f} | Std: {np.std(macro_f1s):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b065d2f2",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26bc44f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 8775/8775 [00:00<00:00, 21424.25 examples/s]\n",
      "Map: 100%|██████████| 976/976 [00:00<00:00, 29575.55 examples/s]\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[I 2025-05-22 23:30:33,291] A new study created in memory with name: no-name-e53db43a-725b-415a-8145-3e1495a15b00\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.153934359550476, 'eval_macro_f1': 0.44391327172288503, 'eval_runtime': 2.1458, 'eval_samples_per_second': 454.843, 'eval_steps_per_second': 56.855, 'epoch': 1.0}\n",
      "{'eval_loss': 1.049004316329956, 'eval_macro_f1': 0.5077304143566147, 'eval_runtime': 2.1895, 'eval_samples_per_second': 445.758, 'eval_steps_per_second': 55.72, 'epoch': 2.0}\n",
      "{'eval_loss': 1.0716345310211182, 'eval_macro_f1': 0.5315036798739128, 'eval_runtime': 2.0108, 'eval_samples_per_second': 485.368, 'eval_steps_per_second': 60.671, 'epoch': 3.0}\n",
      "{'eval_loss': 1.084185242652893, 'eval_macro_f1': 0.5398692464969373, 'eval_runtime': 1.992, 'eval_samples_per_second': 489.952, 'eval_steps_per_second': 61.244, 'epoch': 4.0}\n",
      "{'eval_loss': 1.1194475889205933, 'eval_macro_f1': 0.5406556710965333, 'eval_runtime': 1.9276, 'eval_samples_per_second': 506.336, 'eval_steps_per_second': 63.292, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-22 23:36:53,955] Trial 0 finished with value: 0.5406556710965333 and parameters: {'learning_rate': 1.6560964730246075e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.16496172735944575, 'num_train_epochs': 5, 'warmup_ratio': 0.12206773879748896, 'gamma': 3.0947809303523464, 'alpha': 0.8500357080525651}. Best is trial 0 with value: 0.5406556710965333.\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 379.0472, 'train_samples_per_second': 115.751, 'train_steps_per_second': 3.628, 'train_loss': 0.949353515625, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2337744235992432, 'eval_macro_f1': 0.386367749136275, 'eval_runtime': 1.9261, 'eval_samples_per_second': 506.71, 'eval_steps_per_second': 63.339, 'epoch': 1.0}\n",
      "{'eval_loss': 1.1250355243682861, 'eval_macro_f1': 0.44745996254409065, 'eval_runtime': 2.2606, 'eval_samples_per_second': 431.736, 'eval_steps_per_second': 53.967, 'epoch': 2.0}\n",
      "{'eval_loss': 1.0821396112442017, 'eval_macro_f1': 0.4950272244355017, 'eval_runtime': 1.9331, 'eval_samples_per_second': 504.88, 'eval_steps_per_second': 63.11, 'epoch': 3.0}\n",
      "{'eval_loss': 1.0723201036453247, 'eval_macro_f1': 0.5080069833780952, 'eval_runtime': 1.9229, 'eval_samples_per_second': 507.56, 'eval_steps_per_second': 63.445, 'epoch': 4.0}\n",
      "{'eval_loss': 1.074013590812683, 'eval_macro_f1': 0.5032313620846124, 'eval_runtime': 1.9477, 'eval_samples_per_second': 501.117, 'eval_steps_per_second': 62.64, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-22 23:43:10,598] Trial 1 finished with value: 0.5032313620846124 and parameters: {'learning_rate': 7.446659702105853e-06, 'per_device_train_batch_size': 32, 'weight_decay': 0.17995129031213478, 'num_train_epochs': 5, 'warmup_ratio': 0.10803100587054272, 'gamma': 1.9941768709142853, 'alpha': 1.0251104193872338}. Best is trial 0 with value: 0.5406556710965333.\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 375.5322, 'train_samples_per_second': 116.834, 'train_steps_per_second': 3.661, 'train_loss': 1.113274591619318, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.132463812828064, 'eval_macro_f1': 0.45244138948061063, 'eval_runtime': 1.9607, 'eval_samples_per_second': 497.791, 'eval_steps_per_second': 62.224, 'epoch': 1.0}\n",
      "{'eval_loss': 1.0476115942001343, 'eval_macro_f1': 0.5202146881547375, 'eval_runtime': 1.9619, 'eval_samples_per_second': 497.476, 'eval_steps_per_second': 62.185, 'epoch': 2.0}\n",
      "{'eval_loss': 1.0793198347091675, 'eval_macro_f1': 0.5252289977023892, 'eval_runtime': 2.0248, 'eval_samples_per_second': 482.028, 'eval_steps_per_second': 60.253, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-22 23:47:28,580] Trial 2 finished with value: 0.5252289977023892 and parameters: {'learning_rate': 1.758929535934372e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.052334241760782135, 'num_train_epochs': 3, 'warmup_ratio': 0.18137192522012074, 'gamma': 1.9648258280703064, 'alpha': 1.1655285219192395}. Best is trial 0 with value: 0.5406556710965333.\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 256.9077, 'train_samples_per_second': 102.469, 'train_steps_per_second': 6.411, 'train_loss': 1.0506939404504403, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3140078783035278, 'eval_macro_f1': 0.37184806662981085, 'eval_runtime': 2.1864, 'eval_samples_per_second': 446.4, 'eval_steps_per_second': 55.8, 'epoch': 1.0}\n",
      "{'eval_loss': 1.1659495830535889, 'eval_macro_f1': 0.4182549553480496, 'eval_runtime': 1.9353, 'eval_samples_per_second': 504.327, 'eval_steps_per_second': 63.041, 'epoch': 2.0}\n",
      "{'eval_loss': 1.1206947565078735, 'eval_macro_f1': 0.4484515592756028, 'eval_runtime': 1.9819, 'eval_samples_per_second': 492.446, 'eval_steps_per_second': 61.556, 'epoch': 3.0}\n",
      "{'eval_loss': 1.1123558282852173, 'eval_macro_f1': 0.4541191773339664, 'eval_runtime': 2.0116, 'eval_samples_per_second': 485.185, 'eval_steps_per_second': 60.648, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-22 23:52:30,592] Trial 3 finished with value: 0.4541191773339664 and parameters: {'learning_rate': 5.690886872757119e-06, 'per_device_train_batch_size': 32, 'weight_decay': 0.07723270770616796, 'num_train_epochs': 4, 'warmup_ratio': 0.24849485556838707, 'gamma': 2.3862183012644467, 'alpha': 1.1448942908849347}. Best is trial 0 with value: 0.5406556710965333.\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 300.697, 'train_samples_per_second': 116.729, 'train_steps_per_second': 3.658, 'train_loss': 1.2585398171164772, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1645578145980835, 'eval_macro_f1': 0.4243940805417026, 'eval_runtime': 2.0207, 'eval_samples_per_second': 482.996, 'eval_steps_per_second': 60.375, 'epoch': 1.0}\n",
      "{'eval_loss': 1.089882254600525, 'eval_macro_f1': 0.4588352003988985, 'eval_runtime': 2.1528, 'eval_samples_per_second': 453.367, 'eval_steps_per_second': 56.671, 'epoch': 2.0}\n",
      "{'eval_loss': 1.0917409658432007, 'eval_macro_f1': 0.48196674621147123, 'eval_runtime': 1.936, 'eval_samples_per_second': 504.124, 'eval_steps_per_second': 63.015, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-22 23:57:01,449] Trial 4 finished with value: 0.48196674621147123 and parameters: {'learning_rate': 7.345069575543386e-06, 'per_device_train_batch_size': 16, 'weight_decay': 0.045387279540569134, 'num_train_epochs': 3, 'warmup_ratio': 0.07382889161777294, 'gamma': 2.842237200419467, 'alpha': 0.8249079016461736}. Best is trial 0 with value: 0.5406556710965333.\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 269.4679, 'train_samples_per_second': 97.693, 'train_steps_per_second': 6.112, 'train_loss': 1.1568966687775122, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1306653022766113, 'eval_macro_f1': 0.44411948428859954, 'eval_runtime': 1.9405, 'eval_samples_per_second': 502.959, 'eval_steps_per_second': 62.87, 'epoch': 1.0}\n",
      "{'eval_loss': 1.0524274110794067, 'eval_macro_f1': 0.5156273679009232, 'eval_runtime': 2.0809, 'eval_samples_per_second': 469.038, 'eval_steps_per_second': 58.63, 'epoch': 2.0}\n",
      "{'eval_loss': 1.0725390911102295, 'eval_macro_f1': 0.5365432662997608, 'eval_runtime': 2.0765, 'eval_samples_per_second': 470.014, 'eval_steps_per_second': 58.752, 'epoch': 3.0}\n",
      "{'eval_loss': 1.1100733280181885, 'eval_macro_f1': 0.5579396571928269, 'eval_runtime': 2.0064, 'eval_samples_per_second': 486.434, 'eval_steps_per_second': 60.804, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-23 00:02:58,471] Trial 5 finished with value: 0.5579396571928269 and parameters: {'learning_rate': 1.4859438402215026e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.09179916879381364, 'num_train_epochs': 4, 'warmup_ratio': 0.11700669070517074, 'gamma': 2.0827319414213106, 'alpha': 0.9773781214422633}. Best is trial 5 with value: 0.5579396571928269.\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 355.9966, 'train_samples_per_second': 98.596, 'train_steps_per_second': 6.169, 'train_loss': 0.9638399495887409, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.119063138961792, 'eval_macro_f1': 0.45566613668106504, 'eval_runtime': 2.0048, 'eval_samples_per_second': 486.835, 'eval_steps_per_second': 60.854, 'epoch': 1.0}\n",
      "{'eval_loss': 1.044901728630066, 'eval_macro_f1': 0.5327960493938663, 'eval_runtime': 2.0051, 'eval_samples_per_second': 486.767, 'eval_steps_per_second': 60.846, 'epoch': 2.0}\n",
      "{'eval_loss': 1.1295243501663208, 'eval_macro_f1': 0.52873476421961, 'eval_runtime': 2.0097, 'eval_samples_per_second': 485.636, 'eval_steps_per_second': 60.705, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-23 00:07:25,429] Trial 6 finished with value: 0.52873476421961 and parameters: {'learning_rate': 2.52138803868877e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.09267665560578589, 'num_train_epochs': 5, 'warmup_ratio': 0.1328240236839583, 'gamma': 3.1885291459567116, 'alpha': 0.9974145139453552}. Best is trial 5 with value: 0.5579396571928269.\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 265.918, 'train_samples_per_second': 164.994, 'train_steps_per_second': 10.323, 'train_loss': 1.0257054730191257, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0924794673919678, 'eval_macro_f1': 0.4690632856763562, 'eval_runtime': 1.9949, 'eval_samples_per_second': 489.253, 'eval_steps_per_second': 61.157, 'epoch': 1.0}\n",
      "{'eval_loss': 1.0349279642105103, 'eval_macro_f1': 0.5388244025217929, 'eval_runtime': 2.0476, 'eval_samples_per_second': 476.654, 'eval_steps_per_second': 59.582, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-23 00:10:23,593] Trial 7 finished with value: 0.5388244025217929 and parameters: {'learning_rate': 2.4799124720966066e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.022281555707266205, 'num_train_epochs': 2, 'warmup_ratio': 0.06778440999349795, 'gamma': 2.9814841187970487, 'alpha': 0.8491363281684018}. Best is trial 5 with value: 0.5579396571928269.\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 177.0978, 'train_samples_per_second': 99.098, 'train_steps_per_second': 6.2, 'train_loss': 1.0937086428449454, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1547048091888428, 'eval_macro_f1': 0.4287924687817392, 'eval_runtime': 1.9404, 'eval_samples_per_second': 502.984, 'eval_steps_per_second': 62.873, 'epoch': 1.0}\n",
      "{'eval_loss': 1.0540410280227661, 'eval_macro_f1': 0.506494448660187, 'eval_runtime': 2.0551, 'eval_samples_per_second': 474.906, 'eval_steps_per_second': 59.363, 'epoch': 2.0}\n",
      "{'eval_loss': 1.0655736923217773, 'eval_macro_f1': 0.5209376632802624, 'eval_runtime': 2.0701, 'eval_samples_per_second': 471.482, 'eval_steps_per_second': 58.935, 'epoch': 3.0}\n",
      "{'eval_loss': 1.090766429901123, 'eval_macro_f1': 0.5413630153517894, 'eval_runtime': 1.9674, 'eval_samples_per_second': 496.096, 'eval_steps_per_second': 62.012, 'epoch': 4.0}\n",
      "{'eval_loss': 1.1541903018951416, 'eval_macro_f1': 0.550032209857327, 'eval_runtime': 1.9641, 'eval_samples_per_second': 496.923, 'eval_steps_per_second': 62.115, 'epoch': 5.0}\n",
      "{'eval_loss': 1.1727772951126099, 'eval_macro_f1': 0.552115240975587, 'eval_runtime': 1.9333, 'eval_samples_per_second': 504.839, 'eval_steps_per_second': 63.105, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-23 00:17:59,638] Trial 8 finished with value: 0.552115240975587 and parameters: {'learning_rate': 1.6997893346781543e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.03407414759043114, 'num_train_epochs': 6, 'warmup_ratio': 0.12150033350687926, 'gamma': 2.6691818617092564, 'alpha': 1.0877386871798462}. Best is trial 5 with value: 0.5579396571928269.\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 454.9951, 'train_samples_per_second': 115.716, 'train_steps_per_second': 3.626, 'train_loss': 0.8673211854876894, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1178783178329468, 'eval_macro_f1': 0.4912314617890319, 'eval_runtime': 1.9512, 'eval_samples_per_second': 500.196, 'eval_steps_per_second': 62.525, 'epoch': 1.0}\n",
      "{'eval_loss': 1.0233469009399414, 'eval_macro_f1': 0.5347917593734616, 'eval_runtime': 1.9527, 'eval_samples_per_second': 499.815, 'eval_steps_per_second': 62.477, 'epoch': 2.0}\n",
      "{'eval_loss': 1.0689940452575684, 'eval_macro_f1': 0.5428064528540648, 'eval_runtime': 1.9599, 'eval_samples_per_second': 497.988, 'eval_steps_per_second': 62.249, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-23 00:21:42,287] Trial 9 finished with value: 0.5428064528540648 and parameters: {'learning_rate': 3.352284036261166e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.10181379543053024, 'num_train_epochs': 3, 'warmup_ratio': 0.2868836875685784, 'gamma': 2.1945296415844204, 'alpha': 0.8904692704131193}. Best is trial 5 with value: 0.5579396571928269.\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 221.5308, 'train_samples_per_second': 118.832, 'train_steps_per_second': 3.724, 'train_loss': 1.0498687559185607, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.155316710472107, 'eval_macro_f1': 0.4556099134976141, 'eval_runtime': 2.0518, 'eval_samples_per_second': 475.67, 'eval_steps_per_second': 59.459, 'epoch': 1.0}\n",
      "{'eval_loss': 1.071487307548523, 'eval_macro_f1': 0.5232643774203684, 'eval_runtime': 1.9895, 'eval_samples_per_second': 490.575, 'eval_steps_per_second': 61.322, 'epoch': 2.0}\n",
      "{'eval_loss': 1.0856424570083618, 'eval_macro_f1': 0.5331632538907539, 'eval_runtime': 2.0043, 'eval_samples_per_second': 486.955, 'eval_steps_per_second': 60.869, 'epoch': 3.0}\n",
      "{'eval_loss': 1.1297625303268433, 'eval_macro_f1': 0.5422462030865562, 'eval_runtime': 1.9962, 'eval_samples_per_second': 488.931, 'eval_steps_per_second': 61.116, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-23 00:29:35,332] Trial 10 finished with value: 0.5422462030865562 and parameters: {'learning_rate': 1.0414048521445648e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.1388971779838564, 'num_train_epochs': 4, 'warmup_ratio': 0.20254504044329677, 'gamma': 1.5044207398463671, 'alpha': 0.9418024933164245}. Best is trial 5 with value: 0.5579396571928269.\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 471.5797, 'train_samples_per_second': 74.431, 'train_steps_per_second': 9.305, 'train_loss': 1.0013402140781678, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1624293327331543, 'eval_macro_f1': 0.45849100305893026, 'eval_runtime': 1.9945, 'eval_samples_per_second': 489.357, 'eval_steps_per_second': 61.17, 'epoch': 1.0}\n",
      "{'eval_loss': 1.0770434141159058, 'eval_macro_f1': 0.5277946812625071, 'eval_runtime': 1.9906, 'eval_samples_per_second': 490.307, 'eval_steps_per_second': 61.288, 'epoch': 2.0}\n",
      "{'eval_loss': 1.0743008852005005, 'eval_macro_f1': 0.5517973734018137, 'eval_runtime': 1.9319, 'eval_samples_per_second': 505.193, 'eval_steps_per_second': 63.149, 'epoch': 3.0}\n",
      "{'eval_loss': 1.2131503820419312, 'eval_macro_f1': 0.5425752305709518, 'eval_runtime': 1.9317, 'eval_samples_per_second': 505.248, 'eval_steps_per_second': 63.156, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-23 00:37:17,018] Trial 11 finished with value: 0.5425752305709518 and parameters: {'learning_rate': 1.2623889636755666e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.016194407302142555, 'num_train_epochs': 6, 'warmup_ratio': 0.1608414371633636, 'gamma': 2.6355173373909233, 'alpha': 1.0801361355058683}. Best is trial 5 with value: 0.5579396571928269.\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 460.3414, 'train_samples_per_second': 114.372, 'train_steps_per_second': 14.298, 'train_loss': 0.9790434094049111, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1121466159820557, 'eval_macro_f1': 0.4881039521501224, 'eval_runtime': 1.9418, 'eval_samples_per_second': 502.633, 'eval_steps_per_second': 62.829, 'epoch': 1.0}\n",
      "{'eval_loss': 1.037827730178833, 'eval_macro_f1': 0.5414690580010444, 'eval_runtime': 2.0371, 'eval_samples_per_second': 479.104, 'eval_steps_per_second': 59.888, 'epoch': 2.0}\n",
      "{'eval_loss': 1.1146098375320435, 'eval_macro_f1': 0.5597329182858488, 'eval_runtime': 2.0188, 'eval_samples_per_second': 483.454, 'eval_steps_per_second': 60.432, 'epoch': 3.0}\n",
      "{'eval_loss': 1.216984510421753, 'eval_macro_f1': 0.5223879304982966, 'eval_runtime': 2.016, 'eval_samples_per_second': 484.118, 'eval_steps_per_second': 60.515, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-23 00:42:20,507] Trial 12 finished with value: 0.5223879304982966 and parameters: {'learning_rate': 4.5727504843803065e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.130511363933912, 'num_train_epochs': 6, 'warmup_ratio': 0.09976364410299624, 'gamma': 3.4223169883081113, 'alpha': 1.0807760072406436}. Best is trial 5 with value: 0.5579396571928269.\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 302.4202, 'train_samples_per_second': 174.096, 'train_steps_per_second': 5.456, 'train_loss': 0.8672415438565341, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[I 2025-05-23 00:43:48,652] Trial 13 pruned. \n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1491388082504272, 'eval_macro_f1': 0.42198920237616916, 'eval_runtime': 2.0068, 'eval_samples_per_second': 486.355, 'eval_steps_per_second': 60.794, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[I 2025-05-23 00:45:46,319] Trial 14 pruned. \n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.25123131275177, 'eval_macro_f1': 0.44382785113827566, 'eval_runtime': 1.9985, 'eval_samples_per_second': 488.369, 'eval_steps_per_second': 61.046, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1316993236541748, 'eval_macro_f1': 0.45557366478623457, 'eval_runtime': 1.9974, 'eval_samples_per_second': 488.633, 'eval_steps_per_second': 61.079, 'epoch': 1.0}\n",
      "{'eval_loss': 1.0414968729019165, 'eval_macro_f1': 0.5320871543687261, 'eval_runtime': 2.0039, 'eval_samples_per_second': 487.051, 'eval_steps_per_second': 60.881, 'epoch': 2.0}\n",
      "{'eval_loss': 1.09615159034729, 'eval_macro_f1': 0.5346290691159894, 'eval_runtime': 2.0114, 'eval_samples_per_second': 485.223, 'eval_steps_per_second': 60.653, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-23 00:51:36,814] Trial 15 pruned. \n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1487911939620972, 'eval_macro_f1': 0.5359735837398466, 'eval_runtime': 1.9371, 'eval_samples_per_second': 503.844, 'eval_steps_per_second': 62.981, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[I 2025-05-23 00:52:49,436] Trial 16 pruned. \n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2013399600982666, 'eval_macro_f1': 0.4008580053814591, 'eval_runtime': 1.9507, 'eval_samples_per_second': 500.341, 'eval_steps_per_second': 62.543, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[I 2025-05-23 00:54:02,267] Trial 17 pruned. \n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1546036005020142, 'eval_macro_f1': 0.43231667154205194, 'eval_runtime': 1.9508, 'eval_samples_per_second': 500.301, 'eval_steps_per_second': 62.538, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1326216459274292, 'eval_macro_f1': 0.46317605469997564, 'eval_runtime': 1.9545, 'eval_samples_per_second': 499.366, 'eval_steps_per_second': 62.421, 'epoch': 1.0}\n",
      "{'eval_loss': 1.0346910953521729, 'eval_macro_f1': 0.5353011828792998, 'eval_runtime': 1.9437, 'eval_samples_per_second': 502.14, 'eval_steps_per_second': 62.767, 'epoch': 2.0}\n",
      "{'eval_loss': 1.09611177444458, 'eval_macro_f1': 0.5381201240741416, 'eval_runtime': 1.9486, 'eval_samples_per_second': 500.861, 'eval_steps_per_second': 62.608, 'epoch': 3.0}\n",
      "{'eval_loss': 1.1498173475265503, 'eval_macro_f1': 0.560008628376455, 'eval_runtime': 1.9568, 'eval_samples_per_second': 498.775, 'eval_steps_per_second': 62.347, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-23 00:59:40,085] Trial 18 finished with value: 0.560008628376455 and parameters: {'learning_rate': 2.0997719890677325e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.06767372213238981, 'num_train_epochs': 4, 'warmup_ratio': 0.17678706270920386, 'gamma': 2.328271620594925, 'alpha': 1.1221181393625204}. Best is trial 18 with value: 0.560008628376455.\n",
      "Trying to set gamma in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set alpha in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 336.7261, 'train_samples_per_second': 104.239, 'train_steps_per_second': 6.522, 'train_loss': 0.9224688420530225, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.200172781944275, 'eval_macro_f1': 0.4583378944602635, 'eval_runtime': 1.9971, 'eval_samples_per_second': 488.7, 'eval_steps_per_second': 61.088, 'epoch': 1.0}\n",
      "{'eval_loss': 1.1198277473449707, 'eval_macro_f1': 0.5364590407825842, 'eval_runtime': 1.9412, 'eval_samples_per_second': 502.77, 'eval_steps_per_second': 62.846, 'epoch': 2.0}\n",
      "{'eval_loss': 1.1473878622055054, 'eval_macro_f1': 0.5516849751044562, 'eval_runtime': 1.942, 'eval_samples_per_second': 502.58, 'eval_steps_per_second': 62.822, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-23 01:05:17,307] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2953791618347168, 'eval_macro_f1': 0.5502548761693579, 'eval_runtime': 1.9497, 'eval_samples_per_second': 500.589, 'eval_steps_per_second': 62.574, 'epoch': 4.0}\n",
      "Best trial: BestRun(run_id='18', objective=0.560008628376455, hyperparameters={'learning_rate': 2.0997719890677325e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.06767372213238981, 'num_train_epochs': 4, 'warmup_ratio': 0.17678706270920386, 'gamma': 2.328271620594925, 'alpha': 1.1221181393625204}, run_summary=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\miniconda3\\envs\\LinguaAnimae\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1326216459274292, 'eval_macro_f1': 0.46317605469997564, 'eval_runtime': 1.9375, 'eval_samples_per_second': 503.753, 'eval_steps_per_second': 62.969, 'epoch': 1.0}\n",
      "{'eval_loss': 1.0346910953521729, 'eval_macro_f1': 0.5353011828792998, 'eval_runtime': 1.9565, 'eval_samples_per_second': 498.856, 'eval_steps_per_second': 62.357, 'epoch': 2.0}\n",
      "{'eval_loss': 1.09611177444458, 'eval_macro_f1': 0.5381201240741416, 'eval_runtime': 1.948, 'eval_samples_per_second': 501.014, 'eval_steps_per_second': 62.627, 'epoch': 3.0}\n",
      "{'eval_loss': 1.1498173475265503, 'eval_macro_f1': 0.560008628376455, 'eval_runtime': 1.9476, 'eval_samples_per_second': 501.12, 'eval_steps_per_second': 62.64, 'epoch': 4.0}\n",
      "{'train_runtime': 336.2845, 'train_samples_per_second': 104.376, 'train_steps_per_second': 6.53, 'train_loss': 0.9224688420530225, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, EarlyStoppingCallback\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import Trainer\n",
    "import optuna\n",
    "\n",
    "# 1. Load and shuffle data\n",
    "df = pd.read_csv(\"../data/evaluation/verses_parsed/emotion_verses_labeled_combined.csv\")\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 2. Mapping and validation\n",
    "EMOTION_MAP = {\n",
    "    \"joy\": \"Alegría\",\n",
    "    \"sadness\": \"Tristeza\",\n",
    "    \"anger\": \"Ira\",\n",
    "    \"fear\": \"Miedo\",\n",
    "    \"surprise\": \"Sorpresa\",\n",
    "    \"disgust\": \"Asco\",\n",
    "    \"neutral\": \"Neutral\"\n",
    "}\n",
    "label_list = list(EMOTION_MAP.keys())\n",
    "label2id = {l: i for i, l in enumerate(label_list)}\n",
    "id2label = {i: l for i, l in enumerate(label_list)}\n",
    "df['label'] = df['label'].str.strip().str.lower()\n",
    "invalid_labels = set(df['label'].unique()) - set(label_list)\n",
    "if invalid_labels:\n",
    "    print(f\"❌ ERROR: Detected invalid labels: {invalid_labels}\")\n",
    "    raise ValueError(\"Your CSV contains labels not present in the expected set.\")\n",
    "df['label'] = df['label'].map(label2id).astype(int)\n",
    "\n",
    "# 3. Split into train/test\n",
    "split = int(len(df) * 0.9)\n",
    "df_train = df.iloc[:split].copy()\n",
    "df_test = df.iloc[split:].copy()\n",
    "\n",
    "\n",
    "# 5. Build datasets\n",
    "df_train['label'] = df_train['label'].astype(int)\n",
    "df_test['label'] = df_test['label'].astype(int)\n",
    "ds = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train[['verse', 'label']].rename(columns={'verse': 'text', 'label': 'labels'}), preserve_index=False),\n",
    "    \"test\": Dataset.from_pandas(df_test[['verse', 'label']].rename(columns={'verse': 'text', 'label': 'labels'}), preserve_index=False),\n",
    "})\n",
    "\n",
    "# 6. Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=True)\n",
    "\n",
    "tokenized_datasets = ds.map(preprocess_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# 7. Custom WeightedTrainer\n",
    "\n",
    "def focal_loss(logits, labels, alpha=1.0, gamma=2.0, weight=None):\n",
    "    \"\"\"\n",
    "    Compute focal loss for multi-class classification.\n",
    "    Args:\n",
    "        logits (Tensor): [batch_size, num_classes]\n",
    "        labels (Tensor): [batch_size]\n",
    "        alpha (float or Tensor, optional): Class weighting factor.\n",
    "        gamma (float): Focusing parameter.\n",
    "        weight (Tensor, optional): Class weights (as in CrossEntropyLoss).\n",
    "    \"\"\"\n",
    "    ce_loss = F.cross_entropy(logits, labels, weight=weight, reduction='none')\n",
    "    pt = torch.exp(-ce_loss)\n",
    "    focal = (alpha * (1 - pt) ** gamma * ce_loss)\n",
    "    return focal.mean()\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def __init__(self, *args, weights=None, alpha=1.0, gamma=2.0, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\", None)\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\", None)\n",
    "        if labels is not None and logits is not None:\n",
    "            if not isinstance(labels, torch.Tensor):\n",
    "                labels = torch.tensor(labels)\n",
    "            labels = labels.to(logits.device).long()\n",
    "            # Usamos CrossEntropyLoss sin pesos\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()  # Sin weights\n",
    "            loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "        return (0.0, outputs) if return_outputs else 0.0\n",
    "\n",
    "\n",
    "\n",
    "# 8. Metrics\n",
    "def compute_metrics(pred):\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    labels = pred.label_ids\n",
    "    report = classification_report(labels, preds, target_names=[id2label[i] for i in range(len(label_list))], output_dict=True, zero_division=0)\n",
    "    macro_f1 = report[\"macro avg\"][\"f1-score\"]\n",
    "    return {\"macro_f1\": macro_f1}\n",
    "\n",
    "# 9. Model init for Optuna (returns a fresh model for each trial)\n",
    "def model_init():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"SamLowe/roberta-base-go_emotions\",\n",
    "        num_labels=len(label_list),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "    model.config.problem_type = \"single_label_classification\"  # <-- Aquí\n",
    "    return model\n",
    "\n",
    "# 10. Define Optuna search space\n",
    "def optuna_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 5e-6, 5e-5, log=True),  # Actualizado\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16, 32]),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.01, 0.2),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 6),\n",
    "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0.05, 0.3),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1.5, 3.5), \n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.8, 1.2), \n",
    "    }\n",
    "\n",
    "# 11. TrainingArguments (defaults, will be overridden by Optuna per trial)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_finetuned_bible_optuna\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=2,\n",
    "    logging_strategy=\"no\",\n",
    "    report_to=\"none\",\n",
    "    seed=42,\n",
    "    push_to_hub=False,\n",
    "    disable_tqdm=True,\n",
    ")\n",
    "\n",
    "# 12. Trainer\n",
    "trainer = WeightedTrainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)],\n",
    ")\n",
    "\n",
    "# 13. Run Optuna hyperparameter search\n",
    "best_run = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    n_trials=20, \n",
    "    hp_space=optuna_hp_space\n",
    ")\n",
    "\n",
    "print(f\"Best trial: {best_run}\")\n",
    "\n",
    "# 14. Train final model with best hyperparameters\n",
    "for key, value in best_run.hyperparameters.items():\n",
    "    setattr(trainer.args, key, value)\n",
    "    if key == \"alpha\":\n",
    "        trainer.alpha = value\n",
    "    if key == \"gamma\":\n",
    "        trainer.gamma = value\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"../src/fine_tuning/finetuned-goemotions-bible-optuna\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a75c53",
   "metadata": {},
   "source": [
    "# 6️⃣ Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf6e645",
   "metadata": {},
   "source": [
    "## 5. Evaluation of the Fine-tuned Model\n",
    "\n",
    "Here we analyze the results and compare to previous models.\n",
    "- Macro F1 score on the test set\n",
    "- Confusion matrix\n",
    "- Distribution of predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c47441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         joy      0.599     0.714     0.652       203\n",
      "     sadness      0.673     0.567     0.615       120\n",
      "       anger      0.573     0.543     0.558       138\n",
      "        fear      0.460     0.571     0.510        70\n",
      "    surprise      0.447     0.447     0.447        38\n",
      "     disgust      0.567     0.354     0.436        48\n",
      "     neutral      0.715     0.691     0.703       359\n",
      "\n",
      "    accuracy                          0.625       976\n",
      "   macro avg      0.576     0.555     0.560       976\n",
      "weighted avg      0.630     0.625     0.624       976\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- EVALUATION OF THE FINE-TUNED MODEL ---\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get predictions on the test set\n",
    "preds = trainer.predict(tokenized_datasets[\"test\"])\n",
    "y_true = preds.label_ids\n",
    "y_pred = np.argmax(preds.predictions, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(\n",
    "    y_true, y_pred,\n",
    "    target_names=[id2label[i] for i in range(len(label_list))],\n",
    "    digits=3,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d',\n",
    "            xticklabels=[id2label[i] for i in range(len(label_list))],\n",
    "            yticklabels=[id2label[i] for i in range(len(label_list))],\n",
    "            cmap='Blues')\n",
    "plt.title(\"Confusion Matrix - Fine-tuned Model\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac1a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== False Negatives for 'disgust' ===\n",
      "               verse_id                                              verse  \\\n",
      "8835         judges_9_4  And they gave him threescore and ten pieces of...   \n",
      "8868      proverbs_23_2  And put a knife to thy throat, if thou be a ma...   \n",
      "9074      psalms_116_11             I said in my haste, All men are liars.   \n",
      "9118      1_kings_14_23  For they also built them high places, and imag...   \n",
      "9176         isaiah_2_6  Therefore thou hast forsaken thy people the ho...   \n",
      "9203  ecclesiastes_10_6  Folly is set in great dignity, and the rich si...   \n",
      "9255     leviticus_1_15  And the priest shall bring it unto the altar, ...   \n",
      "9273      proverbs_2_14  Who rejoice to do evil, and delight in the fro...   \n",
      "9288    leviticus_14_37  And he shall look on the plague, and, behold, ...   \n",
      "9299      jeremiah_4_30  And when thou art spoiled, what wilt thou do? ...   \n",
      "\n",
      "     true_label predicted_label  \n",
      "8835    disgust         neutral  \n",
      "8868    disgust            fear  \n",
      "9074    disgust           anger  \n",
      "9118    disgust             joy  \n",
      "9176    disgust           anger  \n",
      "9203    disgust         neutral  \n",
      "9255    disgust         neutral  \n",
      "9273    disgust           anger  \n",
      "9288    disgust         neutral  \n",
      "9299    disgust            fear  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extract_misclassifications(df_test, y_true, y_pred, id2label, top_n=10):\n",
    "    \"\"\"\n",
    "    Extract false positives and false negatives per class.\n",
    "\n",
    "    Args:\n",
    "        df_test (pd.DataFrame): DataFrame with test data, must have 'verse' and 'verse_id'.\n",
    "        y_true (np.array): True labels (ints).\n",
    "        y_pred (np.array): Predicted labels (ints).\n",
    "        id2label (dict): Mapping from label id to label name.\n",
    "        top_n (int): Number of examples to extract per error type and class.\n",
    "\n",
    "    Returns:\n",
    "        dict: {class_label: {'false_positives': DataFrame, 'false_negatives': DataFrame}}\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for label_id, label_name in id2label.items():\n",
    "        # False positives: predicted as label but true label different\n",
    "        fp_mask = (y_pred == label_id) & (y_true != label_id)\n",
    "        fp_examples = df_test[fp_mask]\n",
    "        fp_examples = fp_examples.assign(\n",
    "            true_label=[id2label[t] for t in y_true[fp_mask]],\n",
    "            predicted_label=label_name,\n",
    "            error_type='false_positive'\n",
    "        ).head(top_n)\n",
    "\n",
    "        # False negatives: true label is label but predicted different\n",
    "        fn_mask = (y_true == label_id) & (y_pred != label_id)\n",
    "        fn_examples = df_test[fn_mask]\n",
    "        fn_examples = fn_examples.assign(\n",
    "            true_label=label_name,\n",
    "            predicted_label=[id2label[p] for p in y_pred[fn_mask]],\n",
    "            error_type='false_negative'\n",
    "        ).head(top_n)\n",
    "\n",
    "        results[label_name] = {\n",
    "            'false_positives': fp_examples,\n",
    "            'false_negatives': fn_examples\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage (after evaluation):\n",
    "\n",
    "# df_test must contain at least the columns: 'verse', 'verse_id'\n",
    "# y_true, y_pred are arrays with true and predicted labels (integers)\n",
    "# id2label is a dictionary id -> class name\n",
    "\n",
    "# Here we assume you already have these variables:\n",
    "# df_test, y_true, y_pred, id2label\n",
    "\n",
    "misclassified = extract_misclassifications(df_test, y_true, y_pred, id2label, top_n=10)\n",
    "\n",
    "# To visualize, for example, false negatives of 'disgust':\n",
    "print(\"=== False Negatives for 'disgust' ===\")\n",
    "print(misclassified['disgust']['false_negatives'][['verse_id', 'verse', 'true_label', 'predicted_label']])\n",
    "\n",
    "# You can export to CSV for each class and error type:\n",
    "for label, errors in misclassified.items():\n",
    "    errors['false_positives'].to_csv(f\"false_positives_{label}.csv\", index=False)\n",
    "    errors['false_negatives'].to_csv(f\"false_negatives_{label}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ff1740",
   "metadata": {},
   "source": [
    "# 7️⃣ Inference on New Verses and Comparison with Pretrained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7e785c",
   "metadata": {},
   "source": [
    "## 6. Inference on New Verses\n",
    "\n",
    "We apply the fine-tuned model to new, unseen verses and compare its outputs with those of the original pretrained models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82479a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verse: Jesus wept.\n",
      "  Predicted emotion: sadness\n",
      "  Probabilities: {'joy': 0.004561873, 'sadness': 0.97205263, 'anger': 0.0055633504, 'fear': 0.008343148, 'surprise': 0.0033725249, 'disgust': 0.0031175292, 'neutral': 0.0029888048}\n",
      "\n",
      "Verse: Let there be light.\n",
      "  Predicted emotion: joy\n",
      "  Probabilities: {'joy': 0.9586938, 'sadness': 0.0073417816, 'anger': 0.0024242406, 'fear': 0.0041760285, 'surprise': 0.00557628, 'disgust': 0.0017960677, 'neutral': 0.019991824}\n",
      "\n",
      "Verse: The LORD is my shepherd; I shall not want.\n",
      "  Predicted emotion: joy\n",
      "  Probabilities: {'joy': 0.912757, 'sadness': 0.0027764987, 'anger': 0.003026264, 'fear': 0.0044029593, 'surprise': 0.0015323034, 'disgust': 0.0027971156, 'neutral': 0.072707854}\n",
      "\n",
      "Verse: The serpent deceived me, and I ate.\n",
      "  Predicted emotion: sadness\n",
      "  Probabilities: {'joy': 0.0054140985, 'sadness': 0.6192336, 'anger': 0.060794577, 'fear': 0.16755758, 'surprise': 0.06050903, 'disgust': 0.07681333, 'neutral': 0.009677809}\n",
      "\n",
      "Verse: I'm happy because I passed my exam.\n",
      "  Predicted emotion: joy\n",
      "  Probabilities: {'joy': 0.93436027, 'sadness': 0.020637304, 'anger': 0.007932176, 'fear': 0.0099326195, 'surprise': 0.0114182, 'disgust': 0.008949159, 'neutral': 0.0067703323}\n",
      "\n",
      "Verse: I am happy because I passed the exam.\n",
      "  Predicted emotion: joy\n",
      "  Probabilities: {'joy': 0.9377605, 'sadness': 0.019569518, 'anger': 0.0076239994, 'fear': 0.009638287, 'surprise': 0.010194779, 'disgust': 0.008488562, 'neutral': 0.006724497}\n",
      "\n",
      "Verse: Estoy feliz porque he aprobado el examen\n",
      "  Predicted emotion: sadness\n",
      "  Probabilities: {'joy': 0.009853924, 'sadness': 0.49871224, 'anger': 0.15521677, 'fear': 0.026214454, 'surprise': 0.01691853, 'disgust': 0.26071042, 'neutral': 0.032373648}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Ruta al modelo fine-tuneado\n",
    "MODEL_PATH = \"../src/fine_tuning/finetuned-goemotions-bible-optuna\"\n",
    "\n",
    "# Carga tokenizer y modelo\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "\n",
    "id2label = model.config.id2label\n",
    "label_list = list(id2label.values())\n",
    "\n",
    "# Nuevos versículos\n",
    "new_verses = [\n",
    "    \"Jesus wept.\",\n",
    "    \"Let there be light.\",\n",
    "    \"The LORD is my shepherd; I shall not want.\",\n",
    "    \"The serpent deceived me, and I ate.\",\n",
    "    \"I'm happy because I passed my exam.\",\n",
    "    \"I am happy because I passed the exam.\",\n",
    "    \"Estoy feliz porque he aprobado el examen\"\n",
    "]\n",
    "\n",
    "# Tokeniza\n",
    "inputs = tokenizer(new_verses, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "# Desactiva gradientes para inferencia\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "probs = outputs.logits.softmax(dim=1).detach().numpy()\n",
    "\n",
    "for i, verse in enumerate(new_verses):\n",
    "    pred = id2label[np.argmax(probs[i])]\n",
    "    print(f\"Verse: {verse}\\n  Predicted emotion: {pred}\\n  Probabilities: {dict(zip(label_list, probs[i]))}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdfc5ea",
   "metadata": {},
   "source": [
    "### **(Optional) Compare with old models**\n",
    "- Load your previous model predictions for the same verses (Hartmann, GoEmotions, etc.) and print/plot differences.\n",
    "- Qualitative analysis: Does the fine-tuned model better reflect the context and subtlety of the biblical style?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a69c301",
   "metadata": {},
   "source": [
    "# 8️⃣ Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cd8119",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "- Pretrained emotion models struggle with literary/biblical text (neutral bias, poor fit).\n",
    "- Fine-tuning SamLowe/roberta-base-go_emotions with a small, curated dataset dramatically improves performance.\n",
    "- The new model aligns much better with human annotation and context.\n",
    "- Further improvements could involve a larger dataset, multi-labeling, or expanding the taxonomy of emotions.\n",
    "\n",
    "---\n",
    "\n",
    "**Appendix:**  \n",
    "- Full annotation prompt for GPT-4o:\n",
    "\n",
    "```\n",
    "Assign ONE main human emotion to each Bible verse below. \n",
    "Choose ONLY from this exact list (write just the emotion word in lowercase English, with NO explanations): \n",
    "joy, sadness, anger, fear, disgust, surprise, neutral\n",
    "\n",
    "Return the results in CSV format with columns:\n",
    "id,verse_id,label\n",
    "\n",
    "Do not include the verse text in your answer. \n",
    "Use only the id and verse_id as shown, then your label. Do not add any extra columns, explanations, or blank lines.\n",
    "\n",
    "EXAMPLE OUTPUT:\n",
    "0,2_kings_1_10,anger\n",
    "1,1_samuel_19_21,surprise\n",
    "2,1_chronicles_21_21,neutral\n",
    "\n",
    "VERSES:\n",
    "0,2_kings_1_10,\"And Elijah answered and said to the captain of fifty, If I be a man of God, then let fire come down from heaven, and consume thee and thy fifty. And there came down fire from heaven, and consumed him and his fifty.\"\n",
    "1,1_samuel_19_21,\"And when it was told Saul, he sent other messengers, and they prophesied likewise. And Saul sent messengers again the third time, and they prophesied also.\"\n",
    "2,1_chronicles_21_21,\"And as David came to Ornan, Ornan looked and saw David, and went out of the threshingfloor, and bowed himself to David with his face to the ground.\"\n",
    "3,song_of_solomon_2_4,\"He brought me to the banqueting house, and his banner over me was love.\"\n",
    "4,hosea_4_4,\"Yet let no man strive, nor reprove another: for thy people are as they that strive with the priest.\"\n",
    "5,luke_13_7,\"Then said he unto the dresser of his vineyard, Behold, these three years I come seeking fruit on this fig tree, and find none: cut it down; why cumbereth it the ground?\"\n",
    "6,leviticus_10_10,\"And that ye may put difference between holy and unholy, and between unclean and clean;\"\n",
    "7,lamentations_1_1,\"How doth the city sit solitary, that was full of people how is she become as a widow she that was great among the nations, and princess among the provinces, how is she become tributary\"\n",
    "8,jeremiah_42_3,\"That the LORD thy God may shew us the way wherein we may walk, and the thing that we may do.\"\n",
    "9,numbers_1_48,\"For the LORD had spoken unto Moses, saying,\"\n",
    "```\n",
    "- Data/statistics about annotation agreement  \n",
    "- Example annotation errors and corrections\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LinguaAnimae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
